// a skeleton implementation of a tokeniser

#include "tokeniser.h"
#include <ctype.h>
#include <iostream>

// to shorten the code
using namespace std ;

/////////////////////////////////////////////////////////////////////////

namespace Assignment_Tokeniser
{

    // the current input character, initiliased to '\n'
    // the eof marker can be confused with a legal character but not one accepted by our tokeniser
    static char ch = '\n' ;

    // the number of characters return by nextch() so far
    static int ch_count = 0 ;

    // the current line number and column, initialised to line 0 column 0
    // first call of nextch() will increment the line number to 1
    static int line_num = 0 ;
    static int column_num = 0 ;

    // the line number, column number and ch_count for the first character in the current token
    static int start_line = 0 ;
    static int start_column = 0 ;
    static int start_ch_count = 0 ;

    //control the number of tab
    static int tabNumber = 0;
    
    static char temp = ' ';
    // generate a context string for the given token
    // all lines are shown after the preprocssing of special characters
    // it shows the line before the token, with a '$' marking the end of line,
    // the line containing the token up to the end of the token, and
    // a line of spaces ending with a ^ under the token's first character to mark its position
    // the lines are prefixed by line numbers, right justified in four spaces, followed by ": ", eg "  45: "
    // NOTE: if a token includes newline character(s), only display the token before the first newline followed by a '$'
    // NOTE: this function is not required for the milestone submission
    string token_context(Token token)
    {
        return "" ;
    }

    // read next character if not at the end of input
    // and update the line and column numbers
    static void nextch()
    {
        if ( ch == EOF ) return ;

        if ( ch == '\n' )                   // if last ch was newline ...
        {
            line_num++ ;                    // increment line number
            column_num = 0 ;                // reset column number
        }

        ch = read_char() ;                  // read the next character, probably from stdin but this could change during testing
        column_num++ ;                      // increment the column number

                                            // additional code will be required here to handle preprocessing of '\t' and '\r'
        
                                        
        if (ch == '\t')                     //if input is '\t',
        {
            if (tabNumber < 3)
            {
                repeat_char();              //add 3 more ' '
                // cout << "repeatch " << ch << endl;
                tabNumber++;
                // cout << "tabnum: " << tabNumber << endl;
            }
            else
            {
                tabNumber = 0;
            } 
        }
        
        if (ch == '\r')
        {
            temp = read_char();
            if (temp == '\n')
            {
                ch = temp;
            }
            else
            {
                ch = '\n';
            }
        }
        
                                            // read the next character, probably from stdin but this could change during testing

                                            // for the final submissions you need to buld a line by line copy of the input for use by token_context()
                                            // add the new ch character to the line by line copy here
                                            // ...


        ch_count++ ;                        // one more character read by nextch() ;
    }

    // initialise the tokeniser
    static void initialise()
    {
                                            // add any other initialisation code you need here
                                            // ...

        nextch() ;                          // make first call to nextch to initialise ch
    }

    ////////////////////////////////////////////////////////////////////////

    // NOTE: when creating a new token the length can be calculated as ch_count - start_ch_count
    //       eg new_token(tk_identifier,spelling,start_line,start_column,ch_count - start_ch_count) ;
    //       the eoi token must be given length 0

    // called when we find end of input or an error
    static Token parse_eoi()
    {
        // simulate end of input in case this is handling a bad token rather than a real end of input
        ch = EOF ;

        // return an eoi token
        return new_token(tk_eoi,"",start_line,start_column,0) ;
    }

    static Token parse_wspace(TokenKind kind,string spelling,int line_num, int column_num,int ch_count)
    {
        // always read the next character - we have read past the end of the token
        // cout << "spelling: " << spelling << endl;
        start_ch_count = 1;
        nextch() ;
        // cout << "wspacech: " << ch << endl;

        // return a new Token object
        return new_token(kind,spelling,start_line,start_column,start_ch_count) ;
    }

    static Token parse_identifier()
    {

        string spelling(1,ch);
        if (spelling == "$")
        {
            return parse_eoi() ;
        }
        else{
            start_ch_count = 1;
            // cout << "1spelling:  " << spelling << "\n";
            // cout << "1ch_count: " << ch_count << "\n";
            nextch();

            while (isalnum(ch) || ch == '$' || ch == '.' || ch == '_' )
            {
                spelling += ch ;
                start_ch_count++;
                // cout << "2spelling:  " << spelling << "\n";
                // cout << "1ch_count: " << ch_count << "\n";
                nextch() ;
                // cout << "2ch:  " << spelling << endl;
            }
            //keyword ::= 'do'|'for'|'pointer'|'real'|'this' 
            if (spelling == "do")
            {
                return new_token(tk_do,spelling,start_line,start_column,start_ch_count);

            }
            else if(spelling == "for")
            {
                return new_token(tk_for,spelling,start_line,start_column,start_ch_count);

            }
            else if(spelling == "pointer")
            {
                return new_token(tk_pointer,spelling,start_line,start_column,start_ch_count);

            }
            else if(spelling=="real")
            {
                return new_token(tk_real,spelling,start_line,start_column,start_ch_count);

            }
            else if(spelling=="this")
            {
                return new_token(tk_this,spelling,start_line,start_column,start_ch_count);

            }
            else
            {
                return new_token(tk_identifier,spelling,start_line,start_column,start_ch_count) ;
            }
        }   
    }
    static Token parse_float(string spelling, int start_ch_count)
    {
        //third char
        nextch();
        if(!isdigit(ch))
        {
            return parse_eoi() ;
        }

        if(ch=='0')
        {
            while(ch=='0')
            {
                spelling+= ch;
                start_ch_count++;

                nextch();
            }
            return new_token(tk_float,"0.0",start_line,start_column,start_ch_count) ; 
        }
        else
        {
            while(isdigit(ch))
            {
                spelling+= ch;
                start_ch_count++;
                nextch();
            }
            return new_token(tk_float,spelling,start_line,start_column,start_ch_count) ; 
        }
    }

    static Token parse_scientific(string spelling, int start_ch_count)
    {

    }

    static Token parse_number()
    {
        string spelling = "";
        // cout << "1ch: " << ch << endl;
        start_ch_count = 0;
        //first char
        spelling+=ch;
        start_ch_count++;
        
        if (ch=='0')
        {
            //second char
            nextch();
            if (ch=='.')
            {

                spelling+=ch;
                start_ch_count++;//2

                return parse_float(spelling, start_ch_count);

            }else{
                return new_token(tk_integer,"0",start_line,start_column,start_ch_count) ;

            }
        }
        // 1...9
        else
        {
            //second char
            nextch();

            while(isdigit(ch))
            {
                spelling+=ch;
                start_ch_count++;
                nextch();
            }
            if (ch=='.')
            {
                spelling+=ch;
                start_ch_count++;
                return parse_float(spelling, start_ch_count);
            }
            if(ch == 'e' || ch == 'E')
            {
                spelling+=ch;
                start_ch_count++;
                return parse_scientific(spelling, start_ch_count) ;
            }
            return new_token(tk_integer,spelling,start_line,start_column,start_ch_count) ;
            

        }
    }

        //     while ( isdigit(ch) && ch != '0' || ch =='.' )
        //     {
        //         spelling += ch ;
        //         // cout << "spelling " << spelling <<endl;
        //         start_ch_count++;
        //         nextch() ;
        //         // cout << "whilech " << ch << endl;

        //     }
        //     // return a new Token object
        // return new_token(tk_integer,spelling,start_line,start_column,start_ch_count) ;
    


    static Token parse_symbol(TokenKind kind,string spelling,int line_num, int column_num,int ch_count)
    {
        // always read the next character - we have read past the end of the token
        start_ch_count = 1;
        nextch() ;

        // return a new Token object
        return new_token(kind,spelling,start_line,start_column,start_ch_count) ;
    }

    // return the next Token object by reading more of the input
    // you must read input using the nextch() function
    // the last character read is in the static variable ch
    // always read one character past the end of the token being returned
    Token next_token()
    {
        // if this is the first call of next_token() call initialise()
        if ( line_num == 0 ) initialise() ;

        // remember start of next token
        start_line = line_num ;
        start_column = column_num ;
        start_ch_count = ch_count ;

        switch(ch)      // ch is always the next char to read
        {
                        // add additional case labels here for characters that can start tokens
                        // call a parse_*() function to complete and return each kind of token
                        // this should follow the style used in the workshops
                        // but remember that the token grammar is different in this assignment
        case ' ':       return parse_wspace(tk_space," ",start_line,start_column,start_ch_count) ;
        case '\n':      return parse_wspace(tk_newline,"\n",start_line,start_column,start_ch_count) ;
        case '\t':      return parse_wspace(tk_space," ",start_line,start_column,start_ch_count);

        case 'a'...'z': return parse_identifier() ;
        case 'A'...'Z': return parse_identifier() ;
        case '_':       return parse_identifier() ;    
        case '$':       return parse_identifier() ;

        case'0'...'9':  return parse_number();
        
        case '@':       return parse_symbol(tk_at, "@",start_line,start_column,start_ch_count) ;
        case ';':       return parse_symbol(tk_semi, ";",start_line,start_column,start_ch_count) ;
        case ':':       return parse_symbol(tk_colon, ":",start_line,start_column,start_ch_count) ;
        case '!':       return parse_symbol(tk_not,  "!",start_line,start_column,start_ch_count) ;
        case ',':       return parse_symbol(tk_comma, ",",start_line,start_column,start_ch_count) ;
        case '.':       return parse_symbol(tk_stop,".",start_line,start_column,start_ch_count) ;
        case '{':       return parse_symbol(tk_lcb,"{",start_line,start_column,start_ch_count) ;
        case '}':       return parse_symbol(tk_rcb,"}",start_line,start_column,start_ch_count) ;
        case '(':       return parse_symbol(tk_lrb, "(",start_line,start_column,start_ch_count) ;
        case ')':       return parse_symbol(tk_rrb, ")",start_line,start_column,start_ch_count) ;
        case '[':       return parse_symbol(tk_lsb, "[",start_line,start_column,start_ch_count);
        case ']':       return parse_symbol(tk_rsb, "]",start_line,start_column,start_ch_count);
        case '/':       return parse_symbol(tk_div, "/",start_line,start_column,start_ch_count);
        
        //case '==':      return parse_symbol(tk_eq, "==",start_line,start_column,start_ch_count);
        //case '<=>':     return parse_symbol(tk_spaceship, "<=>",start_line,start_column,start_ch_count);
//        case ''
                        // if EOF or anything unexpected - return eoi
        default:        return parse_eoi() ;
        }
    }
}
